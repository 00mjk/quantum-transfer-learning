{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Quantum-to-classical transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a hybrid network for quantum state classification, developed according to the *quantum-to-classical transfer learning* scheme presented in [1]. \n",
    "\n",
    "## The initial pre-trained quantum network\n",
    "\n",
    "Our starting point is the pre-trained continuous variable (CV) quantum network presented in [_Killoran et al._](https://arxiv.org/abs/1806.06871) [2], _Section IV.D, Experiment C_. The original aim of this network was to encode 7 different 4X4 images, representing the (L,O,T,I,S,J,Z) [_tetrominos_](https://en.wikipedia.org/wiki/Tetromino) (popularized by the video game _Tetris_), in the Fock basis of 7 two-mode quantum states. The input of the quanutm network is one of the following combinations of two-mode coherent states:\n",
    "\n",
    "\\begin{align}\n",
    "|\\varphi_1\\rangle &= |\\alpha\\rangle|\\alpha\\rangle \\\\\n",
    "|\\varphi_2\\rangle &= |-\\alpha\\rangle|\\alpha\\rangle \\\\\n",
    "|\\varphi_3\\rangle &= |\\alpha\\rangle|-\\alpha\\rangle \\\\\n",
    "|\\varphi_4\\rangle &= |-\\alpha\\rangle|-\\alpha\\rangle \\\\\n",
    "|\\varphi_5\\rangle &= |i \\alpha\\rangle| i\\alpha\\rangle \\\\\n",
    "|\\varphi_6\\rangle &= |-i \\alpha\\rangle|i \\alpha\\rangle \\\\\n",
    "|\\varphi_7\\rangle &= |i \\alpha\\rangle|-i \\alpha\\rangle \\\\\n",
    "\\end{align}\n",
    "\n",
    "where the parameter $\\alpha=1.4$ is a fixed constant.\n",
    "\n",
    "The task of the network is to generate an optimal unitary transformation $|\\tilde{\\varphi}_j\\rangle=U|\\varphi_j\\rangle$, such that the probability of finding $i$ photons in the first mode and $j$ photons in the second mode is proportional to the amplitude of pixel $(i,j)$. More precisely, the network is trained to reproduce the tetromino images after projecting the quantum state on the subspace of up to 3 photons. A simulation of the photon number probability distribution and its renormalized subspace projection, are respectively reported in the first and second row of the following figure (taken from Figure 10 of [_Killoran et al._](https://arxiv.org/abs/1806.06871)) [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tetromino images encoded in quantum states. ](static/fig_tetrominos_paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum-to-classical transfer learning\n",
    "\n",
    "With respect to the problem above, we are going to change the dataset and the task in order to give proof-of-principle demonstration of the _quantum-to-classical transfer learning_ method.\n",
    "\n",
    "We assume that the 7 combinations coherent states discussed above are subject to a Gaussian additive noise (random displacements) and that our goal is to correctly guess the original quantum state:\n",
    "\n",
    "\\begin{align}\n",
    "|\\varphi_j & \\rangle   \\xrightarrow{\\text{random displacement}}  \\hat D (\\delta\\alpha_1,\\delta\\alpha_2)|\\varphi_j \\rangle \\\\\n",
    "&\\xrightarrow{\\text{quantum-classical network}} \\text{Outcome: } \\textit{\"the state belongs to class } j\\text{\"}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "In a machine learning language this can be seen as a classification problem with 7 classes and a quantum dataset consisting of randomly displaced coherent states.\n",
    "\n",
    "The starting point of our hybrid model is the CV quantum network presented in the previous section despite it was pre-trained for a quite different task. **The motivation behind this approach is that the image pixels which are produced by the pre-trained network can be considered as classical features possessing a strong correlation with the input state. It is then reasonable to assume that such features can be efficiently post-processed and classified.**\n",
    "\n",
    "The code presented in the next sections is a practical implementation of this idea, which can be summarized in 4 operational steps:\n",
    "\n",
    "1. Remove some quantum layers (0, 1, 2, or more) from the previously described pre-trained quantum network.\n",
    "2. Measure the system in the Fock basis. In this way the quantum circuit acts as a feature extractor.\n",
    "3. Add some final classical layers to post-process the estimated photon-number probability distribution.\n",
    "4. Train only such classical layers to classify the input quantum states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General setup\n",
    "\n",
    "The main imported modules are: the `tensorflow` machine learning framework, the quantum CV \n",
    "software `strawberryfields` [3] and the python plotting library `matplotlib`. All modules should be correctly installed in the system before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "# Strawberryfields (simulation of CV quantum circuits)\n",
    "import strawberryfields as sf\n",
    "from strawberryfields.ops import Dgate, BSgate, Kgate, Sgate, Rgate\n",
    "# Other modules\n",
    "import numpy as np\n",
    "import time\n",
    "# System variables\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # avoid warning messages\n",
    "os.environ['OMP_NUM_THREADS'] = '1'       # set number of threads.\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'  # select the GPU unit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting of the main parameters of the network model and of the training process.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = 2                            # number of modes\n",
    "cutoff = 11                          # must be larger than or equal to 3. Optimal value 11.\n",
    "im_dim = 4                           # subspace dimension\n",
    "dump = 100                           # loggin period\n",
    "images = 7                           # number of images\n",
    "TrainImagesNumber=7                  # number of training images\n",
    "disp_clip = 1                        # max displacement\n",
    "sq_clip = 1                          # max squeezing\n",
    "kerr_clip = 1                        # max kerr non-linearity          \n",
    "sdev = 0.1                           # initial variance of random weights\n",
    "num_test_batches=1000                 # number of test batches used to estimate accuracy\n",
    "\n",
    "noise_scale = 0.6                      # noise strength (mean deviation of random displacements)\n",
    "sub_space = True                       # If True, the state is projected in the 0-3 photons subspace.\n",
    "fine_tune = False                      # If True, also the quantum paramenters alre trained. Suggested value is False.\n",
    "num_epochs = 1000                      # Number of training iterations (number of batches of 7 quantum states).\n",
    "q_depth = 15                           # Number of quantum layers (Max=25).         \n",
    "c_depth = 1                            # Number of classical layers. \n",
    "step = 0.01                            # Learning rate\n",
    "alpha = 1.4                            # Amplitude of coherent states. Note that the quantum network is pre-trained with alpha=1.4.\n",
    "\n",
    "tf.reset_default_graph()              # reset tensorflow graph. Useful to re-run the code.\n",
    "tf.set_random_seed(1)                 # tensorflow random seed\n",
    "rng_data = np.random.RandomState(100) # numpy random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum dataset\n",
    "\n",
    "We define the quantum dataset consisting in the 7 two-mode coherent input states definied at the beginning of this notebook (same as in [_Killoran et al._](https://arxiv.org/abs/1806.06871)), which here we assume to be subject to random displacements sampled from a Gaussian distribution with zero mean and variance `noise_scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which generates a batch of random noise (real values).\n",
    "def noise_sample():\n",
    "    return rng_data.normal(scale=noise_scale, size=images)\n",
    "\n",
    "noise_alpha=tf.placeholder(dtype=tf.complex64, shape=[images])\n",
    "noise_beta=tf.placeholder(dtype=tf.complex64, shape=[images])\n",
    "\n",
    "disps_alpha = tf.constant([alpha, -alpha, alpha, -alpha, 1.0j*alpha, -1.0j*alpha, 1.0j*alpha], dtype = tf.complex64) + noise_alpha\n",
    "disps_beta = tf.constant([alpha, alpha, -alpha, -alpha, 1.0j*alpha, 1.0j*alpha, -1.0j*alpha], dtype = tf.complex64) + noise_beta\n",
    "        \n",
    "labels = [0, 1, 2, 3, 4, 5, 6]\n",
    "# convert labels into TensorFlow format\n",
    "labels_holder = tf.constant(labels,dtype = tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of pre-trained quantum weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the introduction we make use of a pre-trained CV quantum neural network. Such network, originally presented  [_Killoran et al._](https://arxiv.org/abs/1806.06871), was trained to reproduce tetronomos images. The corresponding optimal weights can be loaded from the numpy file `pre_trained\trained_params.npy` that must be present in the notebook directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading of pre-trained weights\n",
    "trained_params_npy = np.load(\"pre_trained\\trained_params.npy\")\n",
    "# conversion into TensorFlow format\n",
    "trained_params = tf.constant(trained_params_npy)\n",
    "\n",
    "# initialization of the variational parameters of the quantum circuit defined later.\n",
    "with tf.name_scope('variables'):\n",
    "        r1 = tf.get_variable(\"r1\", trainable=fine_tune, initializer=trained_params[0])\n",
    "        r2 = tf.get_variable(\"r2\", trainable=fine_tune, initializer=trained_params[1])\n",
    "                \n",
    "        theta1 = tf.get_variable(\"theta1\", trainable=fine_tune, initializer=trained_params[2])\n",
    "        phi1 = tf.get_variable(\"phi1\", trainable=fine_tune, initializer=trained_params[3])\n",
    "                \n",
    "        theta2 = tf.get_variable(\"theta2\", trainable=fine_tune,initializer=trained_params[4])\n",
    "        phi2 = tf.get_variable(\"phi2\", trainable=fine_tune, initializer=trained_params[5])\n",
    "\n",
    "        sqr1 = tf.get_variable(\"sqr1\", trainable=fine_tune, initializer=trained_params[6])\n",
    "        sqphi1 = tf.get_variable(\"sqphi1\", trainable=fine_tune, initializer=trained_params[7])\n",
    "\n",
    "        sqr2 = tf.get_variable(\"sqr2\", trainable=fine_tune, initializer=trained_params[8])\n",
    "        sqphi2 = tf.get_variable(\"sqphi2\", trainable=fine_tune, initializer=trained_params[9])\n",
    "\n",
    "        dr1 = tf.get_variable(\"dr1\", trainable=fine_tune, initializer=trained_params[10])\n",
    "        dphi1 = tf.get_variable(\"dphi1\", trainable=fine_tune, initializer=trained_params[11])\n",
    "\n",
    "        dr2 = tf.get_variable(\"dr2\", trainable=fine_tune, initializer=trained_params[12])\n",
    "        dphi2 = tf.get_variable(\"dphi2\", trainable=fine_tune, initializer=trained_params[13])\n",
    "\n",
    "        kappa1 = tf.get_variable(\"kappa1\", trainable=fine_tune, initializer=trained_params[14])\n",
    "        kappa2 = tf.get_variable(\"kappa2\", trainable=fine_tune, initializer=trained_params[15])\n",
    "\n",
    "Parameters = [r1, r2, theta1, phi1, theta2, phi2, sqr1, sqphi1, sqr2, sqphi2, dr1, dphi1, dr2, dphi2, kappa1, kappa2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid transfer learning model (quantum-to-classical).\n",
    "\n",
    "We first instantiate a _StrawberryFields_ quantum simulator, taylored for simulating a two-mode quantum optical system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Engine, qMode = sf.Engine(num_subsystems=modes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First block: pre-trained quantum neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define, via _StrawberryFields_, the CV quantum neural network model proposed in [_Killoran et al._](https://arxiv.org/abs/1806.06871). \n",
    "\n",
    "With respect to the original version of the network which was designed to have 25 variaitonal layers, here we allow for the possibility of applying only a number `q_depth` of such layers (form 0 up to 25). This is motivated by the idea that the final features of a pre-trained network can be too task-specific, while intermediate features can be more suitable for a transfer learning operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a single variational quantum layer composed of: \n",
    "# beam splitters, squeezing, displacements, Kerr non-linearities, etc.\n",
    "\n",
    "def layer(l):\n",
    "    with tf.name_scope('layer_{}'.format(l)):\n",
    "            BSgate(theta1[l], phi1[l]) | (qMode[0], qMode[1])\n",
    "            Rgate(r1[l]) | qMode[0]\n",
    "\n",
    "            Sgate(tf.clip_by_value(sqr1[l], -sq_clip, sq_clip), sqphi1[l]) | qMode[0]\n",
    "            Sgate(tf.clip_by_value(sqr2[l], -sq_clip, sq_clip), sqphi2[l]) | qMode[1]\n",
    "\n",
    "            BSgate(theta2[l], phi2[l]) | (qMode[0], qMode[1])\n",
    "            Rgate(r2[l]) | qMode[0]\n",
    "\n",
    "            Dgate(tf.clip_by_value(dr1[l], -disp_clip, disp_clip), dphi1[l]) | qMode[0]\n",
    "            Dgate(tf.clip_by_value(dr2[l], -disp_clip, disp_clip), dphi2[l]) | qMode[1]\n",
    "\n",
    "            Kgate(tf.clip_by_value(kappa1[l], -kerr_clip, kerr_clip)) | qMode[0]\n",
    "            Kgate(tf.clip_by_value(kappa2[l], -kerr_clip, kerr_clip)) | qMode[1]\n",
    "\n",
    "# Definition of the complete quantum circuit: state preparation + quantum layers\n",
    "with Engine:\n",
    "        Dgate(disps_alpha) | qMode[0]\n",
    "        Dgate(disps_beta)  | qMode[1]\n",
    "        for i in range(q_depth):\n",
    "                layer(i)\n",
    "                \n",
    "# Simulation of the quantum state evolution              \n",
    "State = Engine.run('tf', cutoff_dim=cutoff, eval=False, batch_size=images)                \n",
    "Ket = State.ket()\n",
    "\n",
    "# Projection on the Hilbert subspace of up to 3 photons.\n",
    "KetReduced = Ket[:, :im_dim, :im_dim]\n",
    "\n",
    "# Renormalize the state\n",
    "norm = tf.sqrt(tf.abs(tf.reduce_sum(tf.conj(KetReduced) * KetReduced, axis=[1, 2])))\n",
    "norm_inv = tf.expand_dims(tf.expand_dims(tf.cast(1.0 / norm, dtype=tf.complex64), axis=[1]), axis=[1])\n",
    "KetProcessed = KetReduced * norm_inv\n",
    "\n",
    "# Convert the state coefficients into images for features visualization.\n",
    "#KetImageOut = tf.expand_dims(tf.abs(KetProcessed), axis=3)\n",
    "#KetImageOutBig = tf.expand_dims(tf.abs(Ket), axis=3)\n",
    "KetImageOut = tf.abs(KetProcessed) ** 2\n",
    "KetImageOutBig = tf.abs(Ket) ** 2\n",
    "\n",
    "# Definition of the classical output of the quantum circuit, i.e. the probabilities of photon number detections.\n",
    "if sub_space == True:\n",
    "        ket_abs =  tf.abs(KetProcessed)\n",
    "        num_features = (cutoff + 1) * (cutoff + 1)\n",
    "else:\n",
    "        ket_abs = tf.abs(Ket)\n",
    "        num_features = im_dim * im_dim\n",
    "        \n",
    "# Flatten to get a classical vector of features\n",
    "ket_abs_flatten = tf.contrib.layers.flatten(ket_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second block: trainable classical network.\n",
    "By following the transfer learning method, we connect the pre-trained quantum block to a final trainable classical network. Depending on the parameter `c_depth`, the classical block is a simple linear classfier (if `c_depth` is 1) or a more complex neural network with `c_depth` dense layers and non-linear activations (_ReLU_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence of fully connected classical layers  \n",
    "c_in = ket_abs_flatten\n",
    "for _ in range(c_depth - 1):\n",
    "        c_in = tf.contrib.layers.fully_connected(c_in,num_features, activation_fn=tf.nn.relu)\n",
    "c_out = tf.contrib.layers.fully_connected(c_in, images, activation_fn=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function, accuracy, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the loss function to minimize\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels_holder, logits = c_out))\n",
    "# Convert logits to labels\n",
    "predictions = tf.argmax(c_out, 1)\n",
    "# Batch accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_holder), tf.float32))\n",
    "# Optimization algorithm\n",
    "optim = tf.train.AdamOptimizer(learning_rate=step)\n",
    "training = optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we just defined the analytic graph of the hybrid network without evaluating it. Now, after initializing a _TensorFlow session_, we can finally run the actual training and testing phases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch: 100, Running loss: 1.752, Running accuracy 0.416, Single batch time 2.659\n",
      "Train batch: 200, Running loss: 1.557, Running accuracy 0.542, Single batch time 3.509\n",
      "Train batch: 300, Running loss: 1.421, Running accuracy 0.607, Single batch time 3.024\n",
      "Train batch: 400, Running loss: 1.320, Running accuracy 0.645, Single batch time 2.364\n",
      "Train batch: 500, Running loss: 1.241, Running accuracy 0.672, Single batch time 3.461\n",
      "Train batch: 600, Running loss: 1.178, Running accuracy 0.693, Single batch time 2.358\n",
      "Train batch: 700, Running loss: 1.127, Running accuracy 0.705, Single batch time 2.448\n",
      "Train batch: 800, Running loss: 1.094, Running accuracy 0.710, Single batch time 3.222\n",
      "Train batch: 900, Running loss: 1.056, Running accuracy 0.719, Single batch time 2.347\n",
      "Test batch: 100, Running loss: 0.724, Running accuracy 0.803, Single batch time 3.075\n",
      "Test batch: 200, Running loss: 0.737, Running accuracy 0.802, Single batch time 2.351\n",
      "Test batch: 300, Running loss: 0.741, Running accuracy 0.802, Single batch time 2.499\n",
      "Test batch: 400, Running loss: 0.740, Running accuracy 0.801, Single batch time 3.479\n",
      "Test batch: 500, Running loss: 0.735, Running accuracy 0.804, Single batch time 2.346\n",
      "Test batch: 600, Running loss: 0.732, Running accuracy 0.807, Single batch time 2.785\n",
      "Test batch: 700, Running loss: 0.736, Running accuracy 0.806, Single batch time 2.955\n",
      "Test batch: 800, Running loss: 0.732, Running accuracy 0.806, Single batch time 2.361\n",
      "Test batch: 900, Running loss: 0.728, Running accuracy 0.807, Single batch time 3.271\n",
      "Model saved in path: ./model.ckpt\n",
      "Training and testing phases completed.\n",
      "RESULTS:\n",
      " train_loss  train_acc  test_loss   test_acc\n",
      "   1.025803   0.725857   0.731280   0.803571\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "test_accuracy = 0.0\n",
    "train_loss = 0.0\n",
    "test_loss = 0.0\n",
    "train_loss_sum = 0.0\n",
    "test_loss_sum = 0.0\n",
    "train_accuracy_sum = 0.0\n",
    "test_accuracy_sum = 0.0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                         \n",
    "                #### training phase ####\n",
    "                for i in range(num_epochs):\n",
    "                        # generate random displacements\n",
    "                        noise_dict = {noise_alpha: noise_sample() + 1.0j * noise_sample(), noise_beta: noise_sample() + 1.0j * noise_sample()}\n",
    "                        rep_time = time.time()\n",
    "                        [_training,_loss,_accuracy] = sess.run([training, loss, accuracy], feed_dict=noise_dict)\n",
    "                        train_loss_sum += _loss\n",
    "                        train_loss = train_loss_sum / (i + 1)\n",
    "                        train_accuracy_sum += _accuracy\n",
    "                        train_accuracy = train_accuracy_sum / (i + 1)\n",
    "                        if (i % dump == 0) and (i != 0):\n",
    "                                print('Train batch: {:d}, Running loss: {:.3f}, Running accuracy {:.3f}, Single batch time {:.3f}'.format(i,train_loss,train_accuracy,time.time()-rep_time))\n",
    "\n",
    "                #### test phase ####\n",
    "                for i in range(num_test_batches):\n",
    "                        # generate random displacements\n",
    "                        noise_dict = {noise_alpha: noise_sample() + 1.0j * noise_sample(), noise_beta: noise_sample() + 1.0j * noise_sample()}\n",
    "                        rep_time = time.time()\n",
    "                        [_loss,_accuracy] = sess.run([loss,accuracy], feed_dict = noise_dict)   ## same as before without training\n",
    "                        test_loss_sum += _loss\n",
    "                        test_loss = test_loss_sum / (i + 1)\n",
    "                        test_accuracy_sum += _accuracy\n",
    "                        test_accuracy = test_accuracy_sum / (i + 1)\n",
    "                        if (i % dump == 0) and (i != 0):\n",
    "                                print('Test batch: {:d}, Running loss: {:.3f}, Running accuracy {:.3f}, Single batch time {:.3f}'.format(i,test_loss,test_accuracy,time.time()-rep_time))\n",
    "                \n",
    "                #### Save model to file ####\n",
    "                save_path = saver.save(sess, \"./model.ckpt\")\n",
    "                print(\"Model saved in path: %s\" % save_path)\n",
    "\n",
    "print('Training and testing phases completed.')\n",
    "print('RESULTS:')\n",
    "print('{:>11s}{:>11s}{:>11s}{:>11s}'.format('train_loss', 'train_acc', 'test_loss', 'test_acc'))\n",
    "print('{:11f}{:11f}{:11f}{:11f}'.format(train_loss, train_accuracy, test_loss, test_accuracy))\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "                # Restore variables from disk.\n",
    "                saver.restore(sess, \"./model.ckpt\")\n",
    "                print(\"Model restored.\")\n",
    "                \n",
    "                noise_dict={noise_alpha: noise_sample() + 1.0j * noise_sample(), noise_beta: noise_sample() + 1.0j * noise_sample()}\n",
    "                [_predictions, _KetImageOut, _KetImageOutBig] = sess.run([predictions, KetImageOut, KetImageOutBig], feed_dict=noise_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we represent the Fock state probabilities as 4X4 images. These are the _features_ extracted by the quantum network and successively processed and classified by by the final classical network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot features as images\n",
    "fig, axs = plt.subplots(nrows=1, ncols=7, figsize = (15, 3))\n",
    "for idx, ax in enumerate(axs.flat):\n",
    "    ax.axis('off')\n",
    "    if idx < 7:\n",
    "        ax.imshow(_KetImageOut[idx], cmap='gray')\n",
    "        ax.set_title('class ' + str(idx + 1) + '\\n' + 'pred. ' + str(_predictions[idx] + 1) , fontsize=22)\n",
    "    #else:\n",
    "    #    ax.imshow(_KetImageOutBig[idx-7], cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Author1, Author2, ... _Transfer learning in hybrid classical-quantum neural networks_. [arXiv:xxxx.xxxx](https://arxiv.org/abs/xxxx.xxxx), (2019).\n",
    "\n",
    "[2] Nathan Killoran, Thomas R. Bromley, Juan Miguel Arrazola, Maria Schuld, Nicolás Quesada, and Seth Lloyd. _Continuous-variable quantum neural networks_. [arXiv:1806.06871](https://arxiv.org/abs/1806.06871), (2018).\n",
    "\n",
    "[3] Nathan Killoran, Josh Izaac, Nicolás Quesada, Ville Bergholm, Matthew Amy, and Christian Weedbrook. _Strawberry Fields: A Software Platform for Photonic Quantum Computing_. [Quantum, 3, 129 (2019)](https://doi.org/10.22331/q-2019-03-11-129)."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
