{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Quantum-to-classical transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a hybrid network for quantum state classification, developed according to the *quantum-to-classical transfer learning* scheme presented in [1]. \n",
    "\n",
    "## The initial pre-trained quantum network\n",
    "\n",
    "Our starting point is the pre-trained continuous variable (CV) quantum network presented in [_Killoran et al._](https://arxiv.org/abs/1806.06871) [2], _Section IV.D, Experiment C_. The original aim of this network was to encode 7 different 4X4 images, representing the (L,O,T,I,S,J,Z) [_tetrominos_](https://en.wikipedia.org/wiki/Tetromino) (popularized by the video game _Tetris_), in the Fock basis of 7 two-mode quantum states. The input of the quanutm network is one of the following combinations of two-mode coherent states:\n",
    "\n",
    "\\begin{align}\n",
    "|\\varphi_1\\rangle &= |\\alpha\\rangle|\\alpha\\rangle \\\\\n",
    "|\\varphi_2\\rangle &= |-\\alpha\\rangle|\\alpha\\rangle \\\\\n",
    "|\\varphi_3\\rangle &= |\\alpha\\rangle|-\\alpha\\rangle \\\\\n",
    "|\\varphi_4\\rangle &= |-\\alpha\\rangle|-\\alpha\\rangle \\\\\n",
    "|\\varphi_5\\rangle &= |i \\alpha\\rangle| i\\alpha\\rangle \\\\\n",
    "|\\varphi_6\\rangle &= |-i \\alpha\\rangle|i \\alpha\\rangle \\\\\n",
    "|\\varphi_7\\rangle &= |i \\alpha\\rangle|-i \\alpha\\rangle \\\\\n",
    "\\end{align}\n",
    "\n",
    "where the parameter $\\alpha=1.4$ is a fixed constant.\n",
    "\n",
    "The task of the network is to generate an optimal unitary transformation $|\\tilde{\\varphi}_j\\rangle=U|\\varphi_j\\rangle$, such that the probability of finding $i$ photons in the first mode and $j$ photons in the second mode is proportional to the amplitude of pixel $(i,j)$. More precisely, the network is trained to reproduce the tetromino images after projecting the quantum state on the subspace of up to 3 photons. A simulation of the photon number probability distribution and its renormalized subspace projection, are respectively reported in the first and second row of the following figure (taken from Figure 10 of [_Killoran et al._](https://arxiv.org/abs/1806.06871)) [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tetromino images encoded in quantum states. ](static/fig_tetrominos_paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum-to-classical transfer learning\n",
    "\n",
    "With respect to the problem above, we are going to change the dataset and the task in order to give proof-of-principle demonstration of the _quantum-to-classical transfer learning_ method.\n",
    "\n",
    "We assume that the 7 combinations coherent states discussed above are subject to a Gaussian additive noise (random displacements) and that our goal is to correctly guess the original quantum state:\n",
    "\n",
    "\\begin{align}\n",
    "|\\varphi_j & \\rangle   \\xrightarrow{\\text{random displacement}}  \\hat D (\\delta\\alpha_1,\\delta\\alpha_2)|\\varphi_j \\rangle \\\\\n",
    "&\\xrightarrow{\\text{quantum-classical network}} \\text{Outcome: } \\textit{\"the state belongs to class } j\\text{\"}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "In a machine learning language this can be seen as a classification problem with 7 classes and a quantum dataset consisting of randomly displaced coherent states.\n",
    "\n",
    "The starting point of our hybrid model is the CV quantum network presented in the previous section despite it was pre-trained for a quite different task. **The motivation behind this approach is that the image pixels which are produced by the pre-trained network can be considered as classical features possessing a strong correlation with the input state. It is then reasonable to assume that such features can be efficiently post-processed and classified.**\n",
    "\n",
    "The code presented in the next sections is a practical implementation of this idea, which can be summarized in 4 operational steps:\n",
    "\n",
    "1. Remove some quantum layers (0, 1, 2, or more) from the previously described pre-trained quantum network.\n",
    "2. Measure the system in the Fock basis. In this way the quantum circuit acts as a feature extractor.\n",
    "3. Add some final classical layers to post-process the estimated photon-number probability distribution.\n",
    "4. Train only such classical layers to classify the input quantum states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General setup\n",
    "\n",
    "The main imported modules are: the `tensorflow` machine learning framework, the quantum CV \n",
    "software `strawberryfields` [3] and the python plotting library `matplotlib`. All modules should be correctly installed in the system before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Strawberryfields (simulation of CV quantum circuits)\n",
    "import strawberryfields as sf\n",
    "from strawberryfields.ops import Dgate, BSgate, Kgate, Sgate, Rgate\n",
    "\n",
    "# Other modules\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# System variables\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # avoid warning messages\n",
    "os.environ['OMP_NUM_THREADS'] = '1'       # set number of threads.\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'  # select the GPU unit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting of the main parameters of the network model and of the training process.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 11                           # must be larger than or equal to 3. Optimal value 11.\n",
    "im_dim = 4                            # subspace dimension\n",
    "dump = 100                            # loggin period\n",
    "num_images = 7                        # number of images\n",
    "disp_clip = 1                         # max displacement\n",
    "sq_clip = 1                           # max squeezing\n",
    "kerr_clip = 1                         # max kerr non-linearity          \n",
    "sdev = 0.1                            # initial variance of random weights\n",
    "num_test_batches=1000                 # number of test batches used to estimate accuracy\n",
    "\n",
    "noise_scale = 0.6                     # noise strength (mean deviation of random displacements)\n",
    "sub_space = True                      # If True, the state is projected in the 0-3 photons subspace.\n",
    "fine_tune = False                     # If True, also the quantum paramenters alre trained. Suggested value is False.\n",
    "num_epochs = 1000                     # Number of training iterations (number of batches of 7 quantum states).\n",
    "q_depth = 15                          # Number of quantum layers (Max=25).         \n",
    "c_depth = 1                           # Number of classical layers. \n",
    "step = 0.01                           # Learning rate\n",
    "alpha = 1.4                           # Amplitude of coherent states. Note that the quantum network is pre-trained with alpha=1.4.\n",
    "\n",
    "tf.reset_default_graph()              # reset tensorflow graph. Useful to re-run the code.\n",
    "tf.set_random_seed(1)                 # tensorflow random seed\n",
    "rng_data = np.random.RandomState(100) # numpy random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum dataset\n",
    "\n",
    "We define the quantum dataset consisting in the 7 two-mode coherent input states definied at the beginning of this notebook (same as in [_Killoran et al._](https://arxiv.org/abs/1806.06871)), which here we assume to be subject to random displacements sampled from a Gaussian distribution with zero mean and variance `noise_scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which generates a batch of random noise (real values).\n",
    "def noise_sample():\n",
    "    return rng_data.normal(scale=noise_scale, size=num_images)\n",
    "\n",
    "noise_alpha=tf.placeholder(dtype=tf.complex64, shape=[num_images])\n",
    "noise_beta=tf.placeholder(dtype=tf.complex64, shape=[num_images])\n",
    "\n",
    "disps_alpha = tf.constant([alpha, -alpha, alpha, -alpha, 1.0j*alpha, -1.0j*alpha, 1.0j*alpha], dtype = tf.complex64) + noise_alpha\n",
    "disps_beta = tf.constant([alpha, alpha, -alpha, -alpha, 1.0j*alpha, 1.0j*alpha, -1.0j*alpha], dtype = tf.complex64) + noise_beta\n",
    "        \n",
    "labels = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# convert labels into TensorFlow format\n",
    "labels_holder = tf.constant(labels,dtype = tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of pre-trained quantum weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the introduction we make use of a pre-trained CV quantum neural network. Such network, originally presented  [_Killoran et al._](https://arxiv.org/abs/1806.06871), was trained to reproduce tetronomos images. The corresponding optimal weights can be loaded from the numpy file `pre_trained\trained_params.npy` that must be present in the notebook directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading of pre-trained weights\n",
    "trained_params_npy = np.load('pre_trained/trained_params.npy')\n",
    "# conversion into TensorFlow format\n",
    "trained_params = tf.constant(trained_params_npy)\n",
    "\n",
    "# initialization of the variational parameters of the quantum circuit defined later.\n",
    "with tf.name_scope('variables'):\n",
    "        r1 = tf.get_variable(\"r1\", trainable=fine_tune, initializer=trained_params[0])\n",
    "        r2 = tf.get_variable(\"r2\", trainable=fine_tune, initializer=trained_params[1])\n",
    "                \n",
    "        theta1 = tf.get_variable(\"theta1\", trainable=fine_tune, initializer=trained_params[2])\n",
    "        phi1 = tf.get_variable(\"phi1\", trainable=fine_tune, initializer=trained_params[3])\n",
    "                \n",
    "        theta2 = tf.get_variable(\"theta2\", trainable=fine_tune,initializer=trained_params[4])\n",
    "        phi2 = tf.get_variable(\"phi2\", trainable=fine_tune, initializer=trained_params[5])\n",
    "\n",
    "        sqr1 = tf.get_variable(\"sqr1\", trainable=fine_tune, initializer=trained_params[6])\n",
    "        sqphi1 = tf.get_variable(\"sqphi1\", trainable=fine_tune, initializer=trained_params[7])\n",
    "\n",
    "        sqr2 = tf.get_variable(\"sqr2\", trainable=fine_tune, initializer=trained_params[8])\n",
    "        sqphi2 = tf.get_variable(\"sqphi2\", trainable=fine_tune, initializer=trained_params[9])\n",
    "\n",
    "        dr1 = tf.get_variable(\"dr1\", trainable=fine_tune, initializer=trained_params[10])\n",
    "        dphi1 = tf.get_variable(\"dphi1\", trainable=fine_tune, initializer=trained_params[11])\n",
    "\n",
    "        dr2 = tf.get_variable(\"dr2\", trainable=fine_tune, initializer=trained_params[12])\n",
    "        dphi2 = tf.get_variable(\"dphi2\", trainable=fine_tune, initializer=trained_params[13])\n",
    "\n",
    "        kappa1 = tf.get_variable(\"kappa1\", trainable=fine_tune, initializer=trained_params[14])\n",
    "        kappa2 = tf.get_variable(\"kappa2\", trainable=fine_tune, initializer=trained_params[15])\n",
    "\n",
    "Parameters = [r1, r2, theta1, phi1, theta2, phi2, sqr1, sqphi1, sqr2, sqphi2, dr1, dphi1, dr2, dphi2, kappa1, kappa2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid transfer learning model (quantum-to-classical).\n",
    "\n",
    "We first instantiate a _StrawberryFields_ quantum simulator, taylored for simulating a two-mode quantum optical system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = sf.Program(2)\n",
    "eng = sf.Engine('tf', backend_options={'cutoff_dim': cutoff, 'batch_size': num_images})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First block: pre-trained quantum neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define, via _StrawberryFields_, the CV quantum neural network model proposed in [_Killoran et al._](https://arxiv.org/abs/1806.06871). \n",
    "\n",
    "With respect to the original version of the network which was designed to have 25 variaitonal layers, here we allow for the possibility of applying only a number `q_depth` of such layers (form 0 up to 25). This is motivated by the idea that the final features of a pre-trained network can be too task-specific, while intermediate features can be more suitable for a transfer learning operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a single variational quantum layer composed of: \n",
    "# beam splitters, squeezing, displacements, Kerr non-linearities, etc.\n",
    "\n",
    "def layer(l):\n",
    "    with tf.name_scope('layer_{}'.format(l)):\n",
    "            BSgate(theta1[l], phi1[l]) | (qMode[0], qMode[1])\n",
    "            Rgate(r1[l]) | qMode[0]\n",
    "\n",
    "            Sgate(tf.clip_by_value(sqr1[l], -sq_clip, sq_clip), sqphi1[l]) | qMode[0]\n",
    "            Sgate(tf.clip_by_value(sqr2[l], -sq_clip, sq_clip), sqphi2[l]) | qMode[1]\n",
    "\n",
    "            BSgate(theta2[l], phi2[l]) | (qMode[0], qMode[1])\n",
    "            Rgate(r2[l]) | qMode[0]\n",
    "\n",
    "            Dgate(tf.clip_by_value(dr1[l], -disp_clip, disp_clip), dphi1[l]) | qMode[0]\n",
    "            Dgate(tf.clip_by_value(dr2[l], -disp_clip, disp_clip), dphi2[l]) | qMode[1]\n",
    "\n",
    "            Kgate(tf.clip_by_value(kappa1[l], -kerr_clip, kerr_clip)) | qMode[0]\n",
    "            Kgate(tf.clip_by_value(kappa2[l], -kerr_clip, kerr_clip)) | qMode[1]\n",
    "\n",
    "# Definition of the complete quantum circuit: state preparation + quantum layers\n",
    "with prog.context as qMode:\n",
    "        Dgate(disps_alpha) | qMode[0]\n",
    "        Dgate(disps_beta)  | qMode[1]\n",
    "        for i in range(q_depth):\n",
    "                layer(i)\n",
    "                \n",
    "# Simulation of the quantum state evolution \n",
    "results = eng.run(prog, run_options={\"eval\": False})  \n",
    "ket = results.state.ket()\n",
    "\n",
    "# Projection on the subspace of up to im_dim-1 photons for each mode.\n",
    "ket_reduced = ket[:, :im_dim, :im_dim]\n",
    "norm = tf.sqrt(tf.abs(tf.reduce_sum(tf.conj(ket_reduced) * ket_reduced, axis=[1, 2])))\n",
    "\n",
    "# Since norm has shape [num_images] while ket_reduced has shape [num_images,im_dim,im_dim]\n",
    "# we need to add 2 extra dimensions to the norm tensor.\n",
    "norm_extended = tf.reshape(norm, [num_images, 1, 1])\n",
    "ket_processed = ket_reduced / tf.cast(norm_extended, dtype=tf.complex64)\n",
    "\n",
    "# Convert the state coefficients into images for features visualization.\n",
    "images_out = tf.abs(ket_processed) ** 2\n",
    "images_out_big = tf.abs(ket) ** 2\n",
    "\n",
    "# Definition of the classical output of the quantum circuit, i.e. the probabilities of photon number detections.\n",
    "if sub_space == True:\n",
    "        ket_abs =  tf.abs(ket_processed)\n",
    "        num_features = (cutoff + 1) * (cutoff + 1)\n",
    "else:\n",
    "        ket_abs = tf.abs(ket)\n",
    "        num_features = im_dim * im_dim\n",
    "        \n",
    "# Flatten to get a classical vector of features\n",
    "ket_abs_flatten = tf.contrib.layers.flatten(ket_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second block: trainable classical network.\n",
    "By following the transfer learning method, we connect the pre-trained quantum block to a final trainable classical network. Depending on the parameter `c_depth`, the classical block is a simple linear classfier (if `c_depth` is 1) or a more complex neural network with `c_depth` dense layers and non-linear activations (_ReLU_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence of fully connected classical layers  \n",
    "c_in = ket_abs_flatten\n",
    "for _ in range(c_depth - 1):\n",
    "        c_in = tf.contrib.layers.fully_connected(c_in,num_features, activation_fn=tf.nn.relu)\n",
    "c_out = tf.contrib.layers.fully_connected(c_in, num_images, activation_fn=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function, accuracy, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the loss function to minimize\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels_holder, logits = c_out))\n",
    "# Convert logits to labels\n",
    "predictions = tf.argmax(c_out, 1)\n",
    "# Batch accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_holder), tf.float32))\n",
    "# Optimization algorithm\n",
    "optim = tf.train.AdamOptimizer(learning_rate=step)\n",
    "training = optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we just defined the analytic graph of the hybrid network without evaluating it. Now, after initializing a _TensorFlow session_, we can finally run the actual training and testing phases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch: 100, Running loss: 1.726, Running accuracy 0.463, Single batch time 2.248\n",
      "Train batch: 200, Running loss: 1.541, Running accuracy 0.579, Single batch time 2.131\n",
      "Train batch: 300, Running loss: 1.411, Running accuracy 0.635, Single batch time 2.248\n",
      "Train batch: 400, Running loss: 1.310, Running accuracy 0.666, Single batch time 2.081\n",
      "Train batch: 500, Running loss: 1.232, Running accuracy 0.692, Single batch time 2.230\n",
      "Train batch: 600, Running loss: 1.171, Running accuracy 0.710, Single batch time 2.262\n",
      "Train batch: 700, Running loss: 1.120, Running accuracy 0.720, Single batch time 2.155\n",
      "Train batch: 800, Running loss: 1.087, Running accuracy 0.726, Single batch time 2.549\n",
      "Train batch: 900, Running loss: 1.049, Running accuracy 0.735, Single batch time 2.011\n",
      "Test batch: 100, Running loss: 0.721, Running accuracy 0.806, Single batch time 2.006\n",
      "Test batch: 200, Running loss: 0.734, Running accuracy 0.804, Single batch time 3.440\n",
      "Test batch: 300, Running loss: 0.738, Running accuracy 0.805, Single batch time 2.279\n",
      "Test batch: 400, Running loss: 0.737, Running accuracy 0.804, Single batch time 2.573\n",
      "Test batch: 500, Running loss: 0.732, Running accuracy 0.807, Single batch time 2.320\n",
      "Test batch: 600, Running loss: 0.729, Running accuracy 0.810, Single batch time 2.236\n",
      "Test batch: 700, Running loss: 0.733, Running accuracy 0.809, Single batch time 2.158\n",
      "Test batch: 800, Running loss: 0.729, Running accuracy 0.811, Single batch time 2.330\n",
      "Test batch: 900, Running loss: 0.725, Running accuracy 0.811, Single batch time 2.434\n",
      "Model saved in path: ./model_q2c.ckpt\n",
      "Training and testing phases completed.\n",
      "RESULTS:\n",
      " train_loss  train_acc  test_loss   test_acc\n",
      "   1.019223   0.739571   0.728380   0.807714\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "test_accuracy = 0.0\n",
    "train_loss = 0.0\n",
    "test_loss = 0.0\n",
    "train_loss_sum = 0.0\n",
    "test_loss_sum = 0.0\n",
    "train_accuracy_sum = 0.0\n",
    "test_accuracy_sum = 0.0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                         \n",
    "                #### training phase ####\n",
    "                for i in range(num_epochs):\n",
    "                        # generate random displacements\n",
    "                        noise_dict = {noise_alpha: noise_sample() + 1.0j * noise_sample(), noise_beta: noise_sample() + 1.0j * noise_sample()}\n",
    "                        rep_time = time.time()\n",
    "                        [_training,_loss,_accuracy] = sess.run([training, loss, accuracy], feed_dict=noise_dict)\n",
    "                        train_loss_sum += _loss\n",
    "                        train_loss = train_loss_sum / (i + 1)\n",
    "                        train_accuracy_sum += _accuracy\n",
    "                        train_accuracy = train_accuracy_sum / (i + 1)\n",
    "                        if (i % dump == 0) and (i != 0):\n",
    "                                print('Train batch: {:d}, Running loss: {:.3f}, Running accuracy {:.3f}, Single batch time {:.3f}'.format(i,train_loss,train_accuracy,time.time()-rep_time))\n",
    "\n",
    "                #### test phase ####\n",
    "                for i in range(num_test_batches):\n",
    "                        # generate random displacements\n",
    "                        noise_dict = {noise_alpha: noise_sample() + 1.0j * noise_sample(), noise_beta: noise_sample() + 1.0j * noise_sample()}\n",
    "                        rep_time = time.time()\n",
    "                        [_loss,_accuracy] = sess.run([loss,accuracy], feed_dict = noise_dict)   ## same as before without training\n",
    "                        test_loss_sum += _loss\n",
    "                        test_loss = test_loss_sum / (i + 1)\n",
    "                        test_accuracy_sum += _accuracy\n",
    "                        test_accuracy = test_accuracy_sum / (i + 1)\n",
    "                        if (i % dump == 0) and (i != 0):\n",
    "                                print('Test batch: {:d}, Running loss: {:.3f}, Running accuracy {:.3f}, Single batch time {:.3f}'.format(i,test_loss,test_accuracy,time.time()-rep_time))\n",
    "                \n",
    "                #### Save model to file ####\n",
    "                save_path = saver.save(sess, \"./model_q2c.ckpt\")\n",
    "                print(\"Model saved in path: %s\" % save_path)\n",
    "\n",
    "print('Training and testing phases completed.')\n",
    "print('RESULTS:')\n",
    "print('{:>11s}{:>11s}{:>11s}{:>11s}'.format('train_loss', 'train_acc', 'test_loss', 'test_acc'))\n",
    "print('{:11f}{:11f}{:11f}{:11f}'.format(train_loss, train_accuracy, test_loss, test_accuracy))\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_q2c.ckpt\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "                # Restore variables from disk.\n",
    "                saver.restore(sess, \"./model_q2c.ckpt\")\n",
    "                print(\"Model restored.\")\n",
    "                \n",
    "                noise_dict={noise_alpha: noise_sample() + 1.0j * noise_sample(), noise_beta: noise_sample() + 1.0j * noise_sample()}\n",
    "                [_predictions, _images_out, _images_out_big] = sess.run([predictions, images_out, images_out_big], feed_dict=noise_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we represent the Fock state probabilities as 4X4 images. These are the _features_ extracted by the quantum network and successively processed and classified by by the final classical network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot features as images\n",
    "fig, axs = plt.subplots(nrows=1, ncols=7, figsize = (15, 3))\n",
    "for idx, ax in enumerate(axs.flat):\n",
    "    ax.axis('off')\n",
    "    if idx < 7:\n",
    "        ax.imshow(_images_out[idx], cmap='gray')\n",
    "        ax.set_title('class ' + str(idx + 1) + '\\n' + 'pred. ' + str(_predictions[idx] + 1) , fontsize=22)\n",
    "    #else:\n",
    "    #    ax.imshow(_KetImageOutBig[idx-7], cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Andrea Mari, Thomas R. Bromley, Josh Izaac, Maria Schuld, and Nathan Killoran. _Transfer learning in hybrid classical-quantum neural networks_. [arXiv:xxxx.xxxx](https://arxiv.org/abs/xxxx.xxxx), (2019).\n",
    "\n",
    "[2] Nathan Killoran, Thomas R. Bromley, Juan Miguel Arrazola, Maria Schuld, Nicolás Quesada, and Seth Lloyd. _Continuous-variable quantum neural networks_. [arXiv:1806.06871](https://arxiv.org/abs/1806.06871), (2018).\n",
    "\n",
    "[3] Nathan Killoran, Josh Izaac, Nicolás Quesada, Ville Bergholm, Matthew Amy, and Christian Weedbrook. _Strawberry Fields: A Software Platform for Photonic Quantum Computing_. [Quantum, 3, 129 (2019)](https://doi.org/10.22331/q-2019-03-11-129)."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
